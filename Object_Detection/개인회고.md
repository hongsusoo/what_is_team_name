
## 모델을 개선하기 위한 고민


1. **문제** : EDA(Data Imbalance) → 비어있는 공간에 Cutmix
    
    **실험** : Battery와 같이 Data 숫자가 부족한 Class가 있어, 이 부분을 보완하기 위해서 Cutmix를활용하여 Data 숫자를 보완(cutmix시 bbox간섭이 안되도로고 비어있는 공간에 cutmix를 진행하여 annotation 추가해줌)
    
    ![image](https://user-images.githubusercontent.com/77658029/142750629-1e8d6880-cdc9-4aa1-8c44-65d450feda90.png)

    **결과** : LB 점수 떨어짐
    
    **분석** : Data Imbalance가 있었지만, 품목의 특징이 뚜렸하여 Model이 구분하는데 큰 어려움이 없었음
    
---

2. **문제** : 다시 EDA - Fusion Matrix 일반쓰레기, paper 구분 불명확
    
    **실험**: Data Cleaning을 통한 annotation 수정 및 삭제하여 불명확한 이미지 조정
    
    ![image](https://user-images.githubusercontent.com/77658029/142750703-bee344c1-cc77-489f-9759-b463707fc6ba.png)
    
    **결과** : LB 점수 떨어짐
    
    **분석** : Competition이 아닌 다른 Task 였으면 성능에 기여가 되었겠지만, Test data 또한 비슷한 Data 형식을 가지고 있기 때문에 Data를 맞춰주는 작업보단. 동일 Object에 대하여 두가지 BBox를 가져가는 것이 mAP점수를 높게 가져갈 수 있음

---

3. **문제** :  Data가 놓여 있는 배경/상황이 여러가지인 경우가 있음
    
    **실험** : 여러가지 Augmentation 기법 테스트 Blur, RandomFog, RandomBrightness, HueSaturation - UniverseNet
    
    ![Untitled](Object%20Detection%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%A9%20ebc8daa10ab7472085f3054764793661/Untitled%203.png)
    
    **결과** : Augmentation 기법에 크게 상관없이 전반적으로 비슷한 경향으로 학습되었고, UniverseNet Baseline과 큰 차이 없었지만, RandomFog에서 약간의 향상이 있었음, Hue Saturation의 경우 가장 효과가 적게 나타남
    
    ![image](https://user-images.githubusercontent.com/77658029/142750762-c6df2d68-5c4e-4413-af1b-bd1090f62553.png)

---

4. **문제** : Data Augmentation
    
    **실험** : 3번에서 효과가 있었던, Blur, RandomFog, RandomBrightness를 모두 추가하여 Test 진행
    
    **결과** :  Baseline 대비해서 LB 점수 떨어짐
    
    **분석** : 여러가지 Augmentation기법을 활용한건 좋았으나, 확률이 높아 여러가지 Augmentation 기법이 한번에 적용되어 오히려 학습에 방해가 되었을 것이라고 판단
    

---

5. **문제** : UniverseNet의 Resize 크기가 일정하게 정해져 있는데, 가로로 큰 사이즈로만 resize를 진행함 → 다른 비율의 객체는 찾기 어려울 것
    
    **실험** : 다른 크기로 Test 하면 어떻게 될지 실험 (base : (1333, 480), (1333, 960), test1 : (480,1333), (960,1333), test2 : (1333, 480), (1333, 960),(480,1333), (960,1333)
    
    **결과** : LB 상 test1에서 큰 차이가 있었음 base : 0.451,  test1 : 0.485, test2 : 0.446
    
    ![image](https://user-images.githubusercontent.com/77658029/142750778-0768ebf5-d6f3-4160-9636-f1fb5216e511.png)
    
    **분석** : BBox의 사이즈 비율이 세로보단 가로가 긴 경우가 조금더 많아, base 보단 test1의 성능 향상에 도움이 된 것으로 사료됨
    
    ![image](https://user-images.githubusercontent.com/77658029/142750789-756ee4ab-33cf-40d8-a968-88cfebbf4fd2.png)
    

---

<br>

## 아쉬운 부분

- Validation Dataset 활용 미흡
    
    : est에 대한 inference를 LB에 의존하다 보니 모델의 평가가 LB만으로 평가되었던것 같다. 그러다보니, Epoch이나  다른 parameter들이 가려져 오히려 더 감에 의존하여 실험하게 되었던것 같다. Validation set을 구축하는 것이 내 모델의 전반적인 학습의 상태/방향을 확인할 수 있는 지표로 삼을 수 있을 것 같다.
    
- Seed 관리 미흡
    
    : 대회 마지막주에 seed가 고정이 안되어 있는걸 확인하였다. Run을 돌릴때마다 seed에 따라 수렴/발산 여부가 결정될 정도로 큰 차이였다. 이런 중요한 parameter를 유동적으로 활용하여 이전까지한 test들의 결과들이 모두 운에 맡겨졌던것 같다.
    새로운 Baseline을 접하게 됐을때 seed가 고정되어 있는지 먼저 확인하는걸 습관화 해야할 것 같다. 
    

<br>

## 자체 평가

mmdection Library를 Baseline으로 사용하였는데, Baseline에 익숙해지는 시간이 오래 걸렸다. 쉽게 여러 모델을 돌려볼 수 있었지만, 크게 의미는 있는 활동이 아니라고 생각하여 Library를 입맛대로 수정하기 위해 여러 시도들을 했지만, 시도에 그쳤던 것 같다.
이후에 동일 Library를 사용하게 된다고 하면 조금은 수월하게 사용할 수 있을 것 같고, 원하는 것을 추가할 수 있을 것 같다.

## 💭 새로운 시도와 목표

- 다양한 EDA 방법 연구 -  더 이상 성능이 오르지 않을 때에는 EDA로 돌아가 새롭게 정의 하자
    1. 배경을 수정하는 방법(2등팀 적용)
    2. Data Cleaning시 최대한 기존데이터는 살리고, 단일로는 점수가 떨어져도 ensemble에서 효과가 있을 수 있음
    3. TTA시 Flip, 좌우, 대각선이 많이 올랐음 → object detection에서는 회전이 제한적이기 때문에 대칭을 잘 활용하는게 중요한 것 같음
- Augmentation 진행 시 너무 많은 기법을 넣을 경우 오히려 성능이 떨어지는 효과가 있는 것으로 보여짐, 적용시키는 확률을 좀 낮게하고, epoch를 늘리는 방향으로 시도해볼 필요가 있을 것 같음
- 다양한 모델 사용 - 단순 mmdetection으로 모델을 돌리기만 하다보니 정확한 모델에 대한 이해없이 결과만 보게되는 것 같음. 처음 baseline model를 찾을 때에 mmdetection으로 여러 모델을 테스트하는 정도로만 사용해야할 것 같음
- 새로운 Baseline 적용시 Seed 확인하기!
- early stopping으로 평가에 들이는 시간 줄이기